{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from base import *\n",
    "from build_model_tf import cascade_model\n",
    "from config import *\n",
    "import base\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = {}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Experiment parameters\n",
    "# --------------------------------------------------\n",
    "\n",
    "# image modalities used (T1, FLAIR, PD, T2, ...) \n",
    "#options['modalities'] = ['T1', 'FLAIR','GADO','DP','T2']\n",
    "options['modalities'] = ['FLAIR','T1','T2']\n",
    "\n",
    "# Select an experiment name to store net weights and segmentation masks\n",
    "options['experiment'] = 'test_CNN'\n",
    "\n",
    "# In order to expose the classifier to more challeging samples, a threshold can be used to to select \n",
    "# candidate voxels for training. Note that images are internally normalized to 0 mean 1 standard deviation \n",
    "# before applying thresholding. So a value of t > 0.5 on FLAIR is reasonable in most cases to extract \n",
    "# all WM lesion candidates\n",
    "options['min_th'] = 0.5\n",
    "\n",
    "# randomize training features before fitting the model.  \n",
    "options['randomize_train'] = True\n",
    "\n",
    "# Select between pixel-wise or fully-convolutional training models. Although implemented, fully-convolutional\n",
    "# models have been not tested with this cascaded model \n",
    "options['fully_convolutional'] = False\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# model parameters\n",
    "# --------------------------------------------------\n",
    "\n",
    "# 3D patch size. So, far only implemented for 3D CNN models. \n",
    "options['patch_size'] = (11,11,11)\n",
    "\n",
    "# percentage of the training vector that is going to be used to validate the model during training\n",
    "options['train_split'] = 0.25\n",
    "\n",
    "# maximum number of epochs used to train the model\n",
    "#options['max_epochs'] = 200\n",
    "\n",
    "options['max_epochs'] = 400\n",
    "\n",
    "# maximum number of epochs without improving validation before stopping training (early stopping) \n",
    "#options['patience'] = 25\n",
    "options['patience'] = 10\n",
    "\n",
    "# Number of samples used to test at once. This parameter should be around 50000 for machines\n",
    "# with less than 32GB of RAM\n",
    "options['batch_size'] = 512\n",
    "#options['batch_size'] = 32\n",
    "\n",
    "# net print verbosity. Set to zero for this particular notebook, but setting this value to 11 is recommended\n",
    "options['net_verbose'] = 1\n",
    "\n",
    "# post-processing binary threshold. After segmentation, probabilistic masks are binarized using a defined threshold.\n",
    "options['t_bin'] = 0.8\n",
    "\n",
    "# The resulting binary mask is filtered by removing lesion regions with lesion size before a defined value\n",
    "options['l_min'] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options['test_name'] = 'cnn_' + options['experiment'] + '.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 11, 11, 11, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 11, 11, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 5, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 5, 5, 5, 64)       55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 190,210\n",
      "Trainable params: 190,018\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_2 (Conv3D)            (None, 11, 11, 11, 32)    2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 5, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 5, 5, 5, 64)       55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 2, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 190,210\n",
      "Trainable params: 190,018\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "options['weight_paths'] = os.getcwd()\n",
    "model = cascade_model(options)\n",
    "model[0].summary()\n",
    "model[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fabe8298eb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preload model weights\n",
    "checkpoint_path1 = \"models/model1.ckpt\"\n",
    "checkpoint_path2 = \"models/model2.ckpt\"\n",
    "model[0].load_weights(checkpoint_path1)\n",
    "model[1].load_weights(checkpoint_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subjects10\n",
      "    --> testing the model\n",
      "Testing subjects14\n",
      "    --> testing the model\n",
      "Testing subjects15\n",
      "    --> testing the model\n"
     ]
    }
   ],
   "source": [
    "# TEST X DATA\n",
    "test_vec = [9,13,14]\n",
    "train_folder = '../data/miccai2016/Preprocessed_training_dataset/'\n",
    "test_x_data = {}\n",
    "for i in test_vec:\n",
    "    subj_name = 's' + str(i+1)\n",
    "    print(\"Testing subject\" + subj_name)\n",
    "    test_x_data[subj_name] = {'FLAIR': train_folder + subj_name + '/FLAIR_preprocessed.nii.gz', \n",
    "    #                         'DP': train_folder + subj_name + '/DP_preprocessed.nii.gz',\n",
    "    #                         'GADO': train_folder + subj_name +  '/GADO_preprocessed.nii.gz', \n",
    "                             'T1': train_folder + subj_name +  '/T1_preprocessed.nii.gz',\n",
    "                            'T2': train_folder + subj_name +  '/T2_preprocessed.nii.gz'}\n",
    "    #                              }\n",
    "\n",
    "\n",
    "    options['test_folder'] = train_folder\n",
    "    options['test_scan'] = subj_name\n",
    "    out_seg = test_cascaded_model(model, test_x_data, options)\n",
    "\n",
    "    out_file_name = '../results/' + subj_name + '_output_segmentation.npy'\n",
    "    np.save(out_file_name,out_seg)\n",
    "    test_x_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FLAIR', 'T1', 'T2'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 224, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load labels\n",
    "n = 50\n",
    "name = \"data/miccai2016_unprocessed/s10/Consensus.nii.gz\"\n",
    "labels = load_nii(name).get_fdata().astype(dtype=np.bool)\n",
    "plt.imshow(labels[n,:,:], cmap='gray')\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fabe045c198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the resulting automatic segmentation\n",
    "my_seg = np.load('../results/s10_output_segmentation.npy')\n",
    "plt.imshow(my_seg[n,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17705108359133126"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import *\n",
    "DSC(my_seg,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.834188034188034"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_dif(my_seg,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09982544185031639"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPR(my_seg, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782051282051282"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPV(my_seg, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DSC: 0.17224895057789213\n"
     ]
    }
   ],
   "source": [
    "test_ndx = [10, 14, 15]\n",
    "dscs = []\n",
    "vds = []\n",
    "tprs = []\n",
    "ppvs = []\n",
    "\n",
    "for ndx in test_ndx:\n",
    "    name = \"../data/miccai2016/Unprocessed_training_dataset/TrainingDataset_MSSEG/s\" + str(ndx) + \"/Consensus.nii.gz\"\n",
    "    labels = load_nii(name).get_fdata().astype(dtype=np.bool)\n",
    "    my_seg = np.load('../results/s'+ str(ndx) + '_output_segmentation.npy')\n",
    "    dscs.append(DSC(my_seg,labels))\n",
    "    vds.append(vol_dif(my_seg,labels))\n",
    "    tprs.append(TPR(my_seg, labels))\n",
    "    ppvs.append(PPV(my_seg, labels))\n",
    "\n",
    "print(\"Mean DSC: {0}\".format(np.mean(dscs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean VD: 30.3708450887265\n",
      "Mean TPR: 0.11482705598916598\n",
      "Mean PPV: 0.7393973408696556\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean VD: {0}\".format(np.mean(vds)))\n",
    "print(\"Mean TPR: {0}\".format(np.mean(tprs)))\n",
    "print(\"Mean PPV: {0}\".format(np.mean(ppvs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
