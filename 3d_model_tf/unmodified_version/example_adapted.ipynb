{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Sclerosis (MS) lesion segmentation of MRI images using a cascade of two 3D convolutional neural networks \n",
    "\n",
    "\n",
    "This script assumes that `Lasagne` and `nolearn` have been installed correctly and `CUDA / CUDNN` are configured. \n",
    "\n",
    "Import libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from base import *\n",
    "from build_model_tf import cascade_model\n",
    "from config import *\n",
    "import base\n",
    "import numpy as np\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration:\n",
    "Configure the model options. Options are passed to the model using the dictionary `options`. The main options are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Experiment parameters\n",
    "# --------------------------------------------------\n",
    "\n",
    "# image modalities used (T1, FLAIR, PD, T2, ...) \n",
    "#options['modalities'] = ['T1', 'FLAIR','GADO','DP','T2']\n",
    "options['modalities'] = ['FLAIR']\n",
    "\n",
    "# Select an experiment name to store net weights and segmentation masks\n",
    "options['experiment'] = 'test_CNN'\n",
    "\n",
    "# In order to expose the classifier to more challeging samples, a threshold can be used to to select \n",
    "# candidate voxels for training. Note that images are internally normalized to 0 mean 1 standard deviation \n",
    "# before applying thresholding. So a value of t > 0.5 on FLAIR is reasonable in most cases to extract \n",
    "# all WM lesion candidates\n",
    "options['min_th'] = 0.5\n",
    "\n",
    "# randomize training features before fitting the model.  \n",
    "options['randomize_train'] = True\n",
    "\n",
    "# Select between pixel-wise or fully-convolutional training models. Although implemented, fully-convolutional\n",
    "# models have been not tested with this cascaded model \n",
    "options['fully_convolutional'] = False\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# model parameters\n",
    "# --------------------------------------------------\n",
    "\n",
    "# 3D patch size. So, far only implemented for 3D CNN models. \n",
    "options['patch_size'] = (11,11,11)\n",
    "\n",
    "# percentage of the training vector that is going to be used to validate the model during training\n",
    "options['train_split'] = 0.25\n",
    "\n",
    "# maximum number of epochs used to train the model\n",
    "options['max_epochs'] = 1\n",
    "\n",
    "# maximum number of epochs without improving validation before stopping training (early stopping) \n",
    "options['patience'] = 1\n",
    "\n",
    "# Number of samples used to test at once. This parameter should be around 50000 for machines\n",
    "# with less than 32GB of RAM\n",
    "options['batch_size'] = 32\n",
    "\n",
    "# net print verbosity. Set to zero for this particular notebook, but setting this value to 11 is recommended\n",
    "options['net_verbose'] = 1\n",
    "\n",
    "# post-processing binary threshold. After segmentation, probabilistic masks are binarized using a defined threshold.\n",
    "options['t_bin'] = 0.8\n",
    "\n",
    "# The resulting binary mask is filtered by removing lesion regions with lesion size before a defined value\n",
    "options['l_min'] = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment configuration:\n",
    "\n",
    "Organize the experiment. Although not necessary, intermediate results, network weights and final lesion segmentation masks are stored inside a folder with name `options['experiment']`. This is extremely useful when a lot of experiments are computed on the same images to declutter the user space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = os.path.join(os.getcwd(), options['experiment'])\n",
    "if not os.path.exists(exp_folder):\n",
    "    os.mkdir(exp_folder)\n",
    "    os.mkdir(os.path.join(exp_folder,'nets'))\n",
    "    os.mkdir(os.path.join(exp_folder,'.train'))\n",
    "\n",
    "# set the output name \n",
    "options['test_name'] = 'cnn_' + options['experiment'] + '.nii.gz'\n",
    "fh = open(\"train_logging/train_stats_full_system.txt\",\"w+\")\n",
    "fh.write(\"something\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data:\n",
    "\n",
    "Training data is internally loaded by the method. So far, training and testing images are passed as dictionaries, where each training image is stored as follows: \n",
    "\n",
    "```\n",
    "traininig_X_data['image_identifier'] = {'modality_1': /path/to/image_modality_n.nii.gz/,\n",
    "                                         ....\n",
    "                                        'modality_n': /path/to/image_modality_n.nii.gz/}\n",
    "```\n",
    "\n",
    "And also for labels: \n",
    "\n",
    "```\n",
    "traininig_y_data['image_identifier_1'] = 'path/to/image_labels.nii.gz/'\n",
    "```\n",
    "\n",
    "**NOTE**: As stated in the paper, input images have been already skull-stripped and bias corrected (N3, etc...) by the user before running the classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FLAIR': '../data/miccai2016/Preprocessed_training_dataset/s1/FLAIR_preprocessed_downsampled.nii.gz'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder = '../data/miccai2016/Preprocessed_training_dataset/'\n",
    "train_mask_folder = '../data/miccai2016/Unprocessed_training_dataset/TrainingDataset_MSSEG/'\n",
    "train_x_data = {}\n",
    "train_y_data = {}\n",
    "\n",
    "# TRAIN X DATA\n",
    "for i in range (1):\n",
    "    subj_name = 's' + str(i+1)\n",
    "    train_x_data[subj_name] = {'FLAIR': train_folder + subj_name + '/FLAIR_preprocessed_downsampled.nii.gz' \n",
    "#                         'DP': train_folder + subj_name + '/DP_preprocessed.nii.gz',\n",
    "#                         'GADO': train_folder + subj_name +  '/GADO_preprocessed.nii.gz', \n",
    "#                         'T1': train_folder + subj_name +  '/T1_preprocessed_downsampled.nii.gz',\n",
    "#                        'T2': train_folder + subj_name +  '/T2_preprocessed_downsampled.nii.gz'}\n",
    "                              }\n",
    "    train_y_data[subj_name] = train_mask_folder + subj_name +  '/Consensus_downsampled.nii.gz'\n",
    "    \n",
    "train_x_data['s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage is 545.120684 MB; Peak was 773.646078 MB\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "\n",
    "X,Y = load_training_data(train_x_data, train_y_data, options, model = None)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(\"Current memory usage is {0} MB; Peak was {1} MB\".format(current / 10**6,peak / 10**6))\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracemalloc.get_tracemalloc_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144580, 11, 11, 11, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144580,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11, 11, 11, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small = X[:1000,:,:,:]\n",
    "Y_small = Y[:1000]\n",
    "X_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-9c83d2e70f23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'modalities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \"\"\"\n\u001b[0;32m   1256\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1258\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "channels = len(options['modalities'])\n",
    "model1 = models.Sequential()\n",
    "fh.write(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "fh.write(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (1) with an unsupported type (<class 'numpy.int32'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-70d248150a34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_paths'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcascade_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\ESL\\ESL_Master\\MS_Deep_Learning\\cnn-ms-lesion-segmentation\\build_model_tf.py\u001b[0m in \u001b[0;36mcascade_model\u001b[1;34m(options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# --------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    176\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2139\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2140\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2141\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2142\u001b[0m       \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2143\u001b[0m       \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop_padding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         data_format=conv_utils.convert_data_format(self.data_format,\n\u001b[1;32m--> 193\u001b[1;33m                                                    self.rank + 2))\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[0mfilter_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m         \u001b[0mspatial_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspatial_dims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         data_format=data_format)\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_build_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, dilation_rate, padding, build_op, filter_shape, spatial_dims, data_format)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;34m\"\"\"Helper class for _with_space_to_batch.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     dilation_rate = ops.convert_to_tensor(\n\u001b[1;32m--> 514\u001b[1;33m         dilation_rate, dtypes.int32, name=\"dilation_rate\")\n\u001b[0m\u001b[0;32m    515\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m       \u001b[0mrate_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[0;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[0;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[1;32m-> 1184\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    225\u001b[0m   \"\"\"\n\u001b[0;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 227\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msseg\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (1) with an unsupported type (<class 'numpy.int32'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "options['weight_paths'] = os.getcwd()\n",
    "model = cascade_model(options)\n",
    "fh.write(model[0].summary())\n",
    "fh.write(model[1].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/200\n",
      "Epoch 2/200\n",
      "Epoch 3/200\n",
      "Epoch 4/200\n",
      "Epoch 5/200\n",
      "Epoch 6/200\n",
      "Epoch 7/200\n",
      "Epoch 8/200\n",
      "Epoch 9/200\n",
      "Epoch 10/200\n",
      "Epoch 11/200\n",
      "Epoch 12/200\n",
      "Epoch 13/200\n",
      "Epoch 14/200\n",
      "Epoch 15/200\n",
      "Epoch 16/200\n",
      "Epoch 17/200\n",
      "Epoch 18/200\n",
      "Epoch 19/200\n",
      "Epoch 20/200\n",
      "Epoch 21/200\n",
      "Epoch 22/200\n",
      "Epoch 23/200\n",
      "Epoch 24/200\n",
      "Epoch 25/200\n",
      "Epoch 26/200\n",
      "Epoch 27/200\n",
      "Epoch 28/200\n",
      "Epoch 29/200\n",
      "Epoch 30/200\n",
      "Epoch 31/200\n",
      "Epoch 32/200\n",
      "Epoch 33/200\n",
      "Epoch 34/200\n",
      "Epoch 35/200\n",
      "Epoch 36/200\n",
      "Epoch 37/200\n",
      "Epoch 38/200\n",
      "Epoch 39/200\n",
      "Epoch 40/200\n",
      "Epoch 41/200\n",
      "Epoch 42/200\n",
      "Epoch 43/200\n",
      "Epoch 44/200\n",
      "Epoch 45/200\n",
      "Epoch 46/200\n",
      "Epoch 47/200\n",
      "Epoch 48/200\n",
      "Epoch 49/200\n",
      "Epoch 50/200\n",
      "Epoch 51/200\n",
      "Epoch 52/200\n",
      "Epoch 53/200\n",
      "Epoch 54/200\n",
      "Epoch 55/200\n",
      "Epoch 56/200\n",
      "Epoch 57/200\n",
      "Epoch 58/200\n",
      "Epoch 59/200\n",
      "Epoch 60/200\n",
      "Epoch 61/200\n",
      "Epoch 62/200\n",
      "Epoch 63/200\n",
      "Epoch 64/200\n",
      "Epoch 65/200\n",
      "Epoch 66/200\n",
      "Epoch 67/200\n",
      "Epoch 68/200\n",
      "Epoch 69/200\n",
      "Epoch 70/200\n",
      "Epoch 71/200\n",
      "Epoch 72/200\n",
      "Epoch 00072: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=options['patience'], verbose=options['net_verbose'])\n",
    "history1 = model[0].fit(X_small, Y_small, batch_size=128, epochs = options['max_epochs'], validation_split=options['train_split'], verbose=options['net_verbose'], callbacks = [earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzsnXmYXFWZ/z+n9q7qrt6Tzp50FrKQhEDEEAFZlEURFEHBGRRGYRwEFXXU8efCKCoyMrg7xnVQFAVFURGHsEUxARICCUnI1tk6nXR6766qrv38/rh1b9det7uruqqT83meepKqurfqdFf1ee+7fV8hpUShUCgUinxYyr0AhUKhUFQ+ylgoFAqFoiDKWCgUCoWiIMpYKBQKhaIgylgoFAqFoiDKWCgUCoWiIMpYKBQKhaIgylgoFAqFoiDKWCgUCoWiILZyL6BYNDU1yblz55Z7GQqFQjGp2LJlS7eUsrnQcSeNsZg7dy6bN28u9zIUCoViUiGEOGTmOBWGUigUCkVBlLFQKBQKRUGUsVAoFApFQZSxUCgUCkVBlLFQKBQKRUGUsVAoFApFQZSxUCgUCkVBTpo+C4VCUUR2PgrHt5d7FZOfmhZY/S8gRPFec+svoC+tNcI7HVbfVLz3yIIyFgqFIpXeA/DQjSBjQBE3uVMOqf1TNwcWvqk4L3l4E/zhQ4k7SZ/NzNXKWCgUiglmw9fBaocP7wDvtHKvZvISDcO3z4JnvgILLi6Od/H0V8DTDB95BRye8b/eKFA5C4VCMULPfnjlV1roRBmK8WFzwPmfgKNbYO//jf/1Dj4HB56FN3x0wg0FKGOhUCiS2fBfYHVoG5Ji/JzxHi0M9fRXQMrxvdYzX4XqqZohLwPKWCgUCo3uvbDt1/C690PN1HKv5uTAaoc3fhKOvQy7/zL21zmwAQ7+Dc69Axzu4q1vFChjoVAoNJ69B2wu5VUUmxXXQf08LXcxFu9CSnj6q1AzDc66sejLM4syFgqFArp2w/aH4OybobrgaAPFaLDa4I2f0kqRX/vT6M9vewYO/wPO/RjYq4q+PLOoaiiFopKIRSAenfj3fearWtJ07Ucm/r1PBZZfC3/7uuYhzB9FZZSUWr7DOwPOfG9p11gAZSwUikrhxC5YdyFEh8vz/ud+DDyN5Xnvkx3du/jdzfCVMVSZvfVesLuKv65RoIyFQlEpPP2VkYRoMTt+zWB1wJnvm9j3PNU4/RoI+yHYP7rzHNUV8dkoY6FQVALHtsGuR7Wrz/M+Vu7VKEqBxVLyLutSohLcCkUl8OzXwFkLa24t90oUiqwoY6FQlJuOl7UqmXM+BFV15V6NQpEVZSwUinLzzN3gqoM1Hyz3ShSKnChjoVCUk6NbYM9fYO1t4Kot92oUipwoY6FQlJNn7oaqeni98ioUlY2qhlJk0rMf2p6G130g9zEv3Q+dOyduTScj0WFNjfTiL4CzptyrUSjyooyFIpM/fkQTLWtaBPPOz3z++Kvw6O1gd4PFPvHrO5mYsgzOvqXcq1AoCqKMhSKVA3/TDAVCaxKbe15mg9gzXwWnFz66TQuhKBSKkx6Vs1CMIKVmCGqmwSVfgsMbNRGzZI69opV5rrlVGQqF4hRCGQvFCAeehUPPaRpBZ98C3pmZQ1ueuTvRPPZv5VunQqGYcJSxUGikq1vanHD+x6H9Bdj/pHZMx1bY/ZhW5qmaxxSKU4qSGgshxGVCiN1CiH1CiE9neX62EOJpIcRWIcQ2IcRbEo+/WQixRQixPfHvRaVcpwLY/xQceV7TJdLVLc/4Z6idPeJdPP1VrXlMlXkqFKccJTMWQggr8F3gcmApcL0QYmnaYZ8FfiOlXAVcB3wv8Xg38DYp5XLgfcDPS7VOBSNeRe0sWHXDyOPJA+efuRv2/hXW3g4ub/nWqlAoykIpPYuzgX1SyjYpZRh4ELgq7RgJ6DtPLdABIKXcKqXsSDy+A3AJIZwlXOupzb71cHQznPdxLfyUjD5w/tm7oaoBXv+v5VmjQqEoK6U0FjOAI0n32xOPJXMn8M9CiHbgMeD2LK/zTmCrlDJUikWe8kgJT38Z6mbDGf+U+bw+XwE0r0I1jykUpySl7LPINr0lfVr59cDPpJT3CiHOAX4uhDhdShkHEEIsA74GXJL1DYS4BbgFYPbs2UVb+CnFnse1xPWV39HCTtlY+R4tV7Ho0oldm0KhqBhK6Vm0A7OS7s8kEWZK4v3AbwCklBsBF9AEIISYCTwCvFdKuT/bG0gp10kpV0spVzc3qyHzo0bPVdTPhZXX5T7OYoElV2hehkKhOCUppbF4EVgohJgnhHCgJbAfTTvmMHAxgBBiCZqx6BJC1AF/Bv5DSvlcCdd4avPan+H4Nm06mzIECoUiDyUzFlLKKHAb8FdgF1rV0w4hxBeFEFcmDvs4cLMQ4hXgV8CNUkqZOG8B8DkhxMuJ25RSrfWUJB7XKpwa5sPyd5V7NQqFosIpqTaUlPIxtMR18mOfT/r/TuANWc67C7irlGs75Xntj9C5Hd6xDqxKIkyhUORHdXCfiuheReNCWH5NuVejUCgmAeqS8lRk5+/hxE5454/BYi33ahQKxSRAGYvgIDyeoURyctP2LDQvhmXvKPdKFArFJEEZi3gUDmwo9yomFosVLrlLeRUKhcI0yli4G+COV8u9CoVCoahoVIJboVAoFAVRxkKhUCgUBVHGQqFQKBQFUcZCoVAoFAVRxkKhUCgUBVHGQqFQKBQFUcZCoVAoFAVRxkKhUCgUBVHGQqFQKBQFUcZCoVAoFAVRxkKhUCgUBVHGQqFQKBQFUcZCoVAoFAVRxkKhUCgUBVHGQqFQKBQFUcZCoVAoFAVRxkKhUCgUBVHGQqFQKBQFUcZCoVAoFAVRxkKhUCgUBVHGQqGYID7zyHY++/vtozrn+nWbWLdhf4lWpFCYx1buBSgUpwpbD/eP6nh/KMrGth4aPI4SrUihMI8yFgrFBDEQCBOT0vTxe0/4AOgLhEu1JIXCNMpYKBQTRP9whHA0jpQSIUTB4/d0DgHQ61fGQlF+VM5CoZgAwtE4gXCMaFwyOBw1dc7ehLHoD0RKuTSFwhTKWCgUE8DA8MiG3+MPmTpnd6cWhuoNhJGjCF8pFKVAGQuFYgIYGB4JJfWYDCvpnkU4Gmc4EivJuhQKsyhjoVBMACmeha+wsRgMRjg2EGRuoxtQeQtF+SmpsRBCXCaE2C2E2CeE+HSW52cLIZ4WQmwVQmwTQrwl6bn/SJy3WwhxaSnXqVCUmuS8g5kw1N5ECOr18xozzlcoykHJjIUQwgp8F7gcWApcL4RYmnbYZ4HfSClXAdcB30ucuzRxfxlwGfC9xOspFJOS5M2+14RnoYegzp7XoJ2jPAtFmSmlZ3E2sE9K2SalDAMPAlelHSMBb+L/tUBH4v9XAQ9KKUNSygPAvsTrKRSTEj0MZbUIUzmLPZ0+quxWls+sBVSvhaL8lNJYzACOJN1vTzyWzJ3APwsh2oHHgNtHca5CMWnoH44gBMyoq6LbVzgMtadziIVTq2lMdG+rMJSi3JTSWGTrOkqv/7se+JmUcibwFuDnQgiLyXMRQtwihNgshNjc1dU17gUrFKViIBDG67LTXOM0FVLa0znEwik11FbZARWGUpSfUhqLdmBW0v2ZjISZdN4P/AZASrkRcAFNJs9FSrlOSrlaSrm6ubm5iEtXKIrLwHCEOredBo+jYDXUQCDCiaEQi6ZWY7Na8Lps9KswlCIHE9WDU0pj8SKwUAgxTwjhQEtYP5p2zGHgYgAhxBI0Y9GVOO46IYRTCDEPWAi8UMK1KhQlpX84Qm2VnaZqR8GcxZ4TWnJ70dQaABo8DnpVGEqRg9t+tZX3/aT022PJjIWUMgrcBvwV2IVW9bRDCPFFIcSVicM+DtwshHgF+BVwo9TYgeZx7AQeBz4kpVRdSYpJS39AMxaNHid9gTDxeO6rQV0TauHUagDq3A7lWShy8urRAdyO0heLllRIUEr5GFriOvmxzyf9fyfwhhznfhn4cinXp1BMFIPDEWY1uGnwOIjFJQPDEepzSI/v7fThcViZUVcFaJ5F52BwIpdbNnQjarEUFlpUaM2bh3oCXHvWzJK/l+rgPsn4r7++xvXrNpV7GYo0tDCUjcZqzUDka8zbfXyIhVNrDGXaOrf9lKmGevv3nuOuP+8yfXw0FmfNV57kdy+1l3BVlcuujkEAlk2vLfl7KWNxkrG302eEMRSVgZSaJ1FX5aDR4wSgO0+Se++JIRYlQlAADW7HKdFnMTAcYVv7AL9+8TCBsDll3l5/mOODQfYkOt5PNXYe04zF0uneAkeOH2UsTjIC4RiDwcikUCnt9YdPiVi8LxQlFpfUue2GZ5GrFLbXH6bbFzaS2wD1HgeBcIzgSS4muCux8fnDMf6y/bipc3SjOxg8NTyvdHZ0DNJU7WBKjbPk76WMxUmGPxwlEpMEI/FyL6UgH/31y3zy4W3lXkbJ0UNI3qoRY9GTozFvJLmdZCzcp0Zj3s5ESKWp2slDW44UOFpDN7qDwyf37yYXOzsGWTLNa2qY1nhRxuIkwx/S3PfJcKV1rH+Ygz3+ci+j5OhSH3VVdmPjz1U+q2tCJYeh6t2nRmPejo5Bmmuc3Lh2DpvaejncEyh4jp77GQyaC1udTISjcfaeGJqQfAWYMBZCiNuEEPUTsRjF+PGHtFDFwCS40vKFonQNmRsENJkxjIXbgd1qoc5tz9mYt6fTR43LRovXZTxWZ3gWpTEWsbjkyV2dRGLl9UZ3dAywbLqXq8+ciRDwsImktf57nAzf92Kz98QQkZhk2QTkK8CcZ9ECvCiE+E1CclzVtFUwemJwMrjlQ8EofQFtLvXJjB4+0qU7GjyOnNVQezqHWJRUCaUfD9rEvFLwjfV7eP//buZnzx0syeubIRSNse+Ej6XTvEyvq+LcBU38dkt73n4UGPEshibB973Y7OiYuOQ2mDAWUsrPonVQ/xi4EdgrhPiKEGJ+idemGAP+sOZZVHoYKh6X+BIhMzPCepOZ/sSUvLpEOKnJ48zqWUgpE8aiOuVxPQzVV4KcxTO7T/Dtp/ZhEfDQliNlK4zY2+kjGpdGSOXa1bM42j/MP/b35D2v5xROcO/sGMTtsDK30TMh72cqZyG1b9DxxC0K1AMPCyHuKeHaFKMkEosbV+mDw5Udw/UnlUae7KEoPUSS6llkGotuX5i+QISFU2pSHtfDUH1Fzll09A9zx69fZnFLDZ9961L2dPrY1j5Q1Pcwy860q+RLlk7F67IVTHT3GAnuqGlDF4tLvv3kXgYqoGDgDy8fZcuh3jGdu7NjkMUtNVgnqIHRTM7iw0KILcA9wHPAcinlvwFnAe8s8foUoyAQHimtrPQrraHgKWQsAhGcNgsuuybJ0FjtyJqsHklupxoLh81CtdNW1F6LSCzO7b/aSjga57v/dCbXrJ6Jy24xXYVUbHZ0DOBxWJnToI2RddmtXHXGDB5/9XjefIReVRaOxQmZDGe+dnyQe5/Yw5+3Hxv/wsfJl/60i/ue2Dvq8+Jxyc5jgxOW3AZznkUTcLWU8lIp5UNSygiAlDIOXFHS1SlGRXIjUyVcNeVDD0EBnDjJjUV/IGKEoAAaqzV9qFhaPF4vm13UkhqGAqj3FLeL+57HX2PLoT7ufucK5jdX43XZuWxZC4++3FGWfo6dx7QS0GSZj2tXzyQUjfOnbRmC0wbJRtdsklv/2zjUW95KvFhc0usP8cqR/oK5mXSO9AXwhaITltwGc8biMcDwk4QQNUKI1wNIKc335StKjj9pA658z2JkfSe9Z5Ho3tZp9DiQMnP63Z4TPurcdpqrMxus6t3ZvZH2vgC3PrAl5bMvxN/3dvPDvx3gvefM4W0rpxuPX7t6FoPBKP+3s9P0axWDeFyys2MwY+NbPqOW06bW8PCW3FVRPb4wTYnfl9miDt2omCnNLSU9vhBxCUOhKPu7RteBPtHJbTBnLL4PJP8k/sRjigpDL5uFys9ZpIShfCe3SF7/cNjIVwBJjXlpxuL4EIum1GRtsKrPoTz79GsneGz78VHlGv664zjVThv/761LUh4/p7WRGXVVPLR5YkNRh3oD+MOxjJCKEILzFzWxo2Mwaz4iFI0xFIrS2qQleM1eIOnG4lCZjUWyR731SP+ozt3ZMYjVIjJClqXEjLEQMumTSoSfSqpWqxgbyUnjSvcs9DCUzSJOes+iPxChNikMpZfCJndx65VQC6dmhqBAq4jKVjq7v0sLpRzpM7/x7Tw2yNJpXpy2VFlri0XwzrNm8vd93RztHzb9euMlPbmdzLTaKsLReNZKMN3Tmtuk5TnMXiDpfxuHevxllcXpSvr8tx4enbHY0THAwinVRh5sIjBjLNoSSW574vYRoK3UC1OMnkDCs3DYLBVvLHTPYnaj+6TIWezoGODie5/JGioaHI5Ql+RZ6GGT5IqoE0MhBoPRnFeKdW4H/f7Mz7StWzMW7X3mNvdYXLLr2GDO8MW1Z81ESvhdntBPsdnRMYDNIrIaymm1WnPi8YFM71P3zOY1aeeN1rPwh2MFB1GNh1+/eJhL79tAKJo9B9Q1qH3v5zV5eHmUnsWODs3gTyRmjMUHgbXAUbRxp68HbinlohRjQ/csptW6Kr6j1ZcwFq1N1SeFZ/GPfT3s7/Kz/WhmOEifkqfTmMWzSB94lE6Dx8FQKJrRwNiWiHW3m/QsDvX4CYRjOY3FrAY3a1obePil9gm76t55bJAFU6ozPB2AFt1YDGYaQ32jn5cIQ5lOcCcdV6pQ1Lb2fj73+x3s7hziWH/2MKvuWVyydCq7jw+azjt1DYU4MRSa0HwFmGvKOyGlvE5KOUVKOVVK+R4p5YmJWJxidOilsy1e1yTIWUQQAuY2uukaCk0Kldx8tHVrm/bhNK2rUDRGIBxLqYaqczsQIrWSR5fYPi2HZ6E35ukNfgDBSMwIF7X3mvMsdhjzD3JvNNeeNYtDPQFeODC2+v/RsqMjdwmobiyOZfUsRq7MYTQJ7ii2RNXVoRJokw0EItz6wEvG/WxrB23Tr3HZWNPaSFxiOu80kbLkyZjps3AJIT4khPieEOIn+m0iFqcYHfqVybRaV+WHoUJRqp02pnpdhKJxhkZRzVOJ6LmD9CtVoyHPPVINZbUIGtwOupONxfEhGj0OGrNUQgHGVL3k8tmDPX6kBLfDatqz2NExiN0qMhr/krl8eQseh5Xfv3zU1GuOhxNDQbryXCU3VzuxiPxhqGl1Llx2i2kxwYHhCAumVCNE8T0LKSUff+gVOgeD3P3O5QA5pxx2DYVornFyxqw6ANOhKD3Hs2zaxPVYgLkw1M/R9KEuBZ4FZgJquk4FYngWtVUMDlf2TAtfMEqN00ZzQof/xODkDkW1JYzFwbTNZzCte1unweOgN6kaas+J3MltGJEpT/ZGDiTec+38Ro4NBk1pbO08NsjCKTU4bLn/9N0OG+fMbyootVEMdhbwdGxWC1NqXNmNhT+M3SqocdrwuuyjKp1trnEyvbaKw73FNRY//Fsb63d18h+XL+Gy01uA3J7FiaEgzdVO6j0O5ja62Xq4z9R77OgYYGZ9VUrRxERgxlgskFJ+DvBLKf8XeCuwvLTLmnzs7Rwqe57AH4risFlo9DiIyxGdqEpkKBil2mUzhraUM28RCEfZfXzs1z+DwYihb3U4rdFL9wTq0oxFY/WImKCUkn2dvrxlkPVZlGf15PZ5C5uREo4N5A9FSSnZ2TFgKnxxzvxGDvUE6ChxVZQeFluSJ1nbUuvieJar8x5fiEaPEyEE3iq7aW96cDiCt8rOnEZ3USXyNx/s5WuP7+by01u46Q1zcTtseF02juf4XLqGQkxJqAuvml3P1iP9pi7w9Gq2icaMsdA/gX4hxOlALTC3ZCuahEgpufYHG3nvT14oq4KqPxzF47DirdIqm8ttvPLhC0WpcdkNz6KrjGKCP/n7Ad76rb8V3GxzoXsVsxvcHO4NpHTjGsbCnW4sRsQEjw0EGQpFUwYepVPv0WdajHym+7t8tHhdhpEpVBHVNRSi2xc21fV7TmsjABtL7F3sPDbIrIaqDM8rmRavK+vVea8/bJQh11bZR5Xgrk0Yi2I25n3t8ddo8br42jUrjF6ZabVVeXMWegPmGbPq6BoK0ZHjWJ22Lh8Huv2sTISuJhIzxmJdYp7FZ4FHgZ3A10q6qklGXyBCfyDCK0f6+cpj5WtqD4RieBIuOVS2TPlQMEJ1ShiqfI15OzoGicYlv3tpbDH6A4nk9kWLpxCMxFNKgdNFBHUak8QEDZmPKYXDUMld321dflqbPcysrwLgSIGQitH1a+KqdHFLDXVuOxvbSmwsOgYLxt5barOHobr9YaPB0euymSrq0Oeha8bCQ48/nKImMFb8oShbD/dz5RnTjb8/fe3Zchb+UBR/OGZ8/1fNTuQtCvRbfOvJvbhsVt61eta41zxa8hoLIYQFGJRS9kkpN0gpWxNVUT+YoPVNCvQ/0iXTvPzsHwd5rEwCZZpnYcNbNQmMRShKjctGbZUdh9UyZs9if5ePf+zvHtdadic264c2j02iu63Lj9UiOG9hE5BaYdNvTMlzpJzT6HEyMBwhEouPGIs8noXLbqXKbjWUZ6WUtHX5aG32MK3WhdUiCnoWo6misVgEr5/XwKYSGgtfKMrBHn/B9UyrdeELRTM2dS0MlTAWJsNQgXCMWFxqxiIhWliMJPfmQ31E45I1CY9MJ5dXpIdddWOxuMWLw2bJm7fYd2KIR1/p4L3nzDHOm0jyGotEt/ZtE7SWSYv+R/q1dy5n1ew6PvnwNg50T7xIWSAcw+20jngWFTxq0hfUjIUQguYa55hzFvc9sYeP/fqVMa8jFI1xqCeQiF8HePGguSRjMm1dfmbVVzG/WfMMDiVd4Q8EwggBNa5U0YOG6hHZ8T2dPpprnEbFUy7q3Xajk7nHH2YwGKW1qRqb1cK0WlfBLu4dHQPMaXRT4zKXGD2ntZH2vuGCHstY2XF0ACnzl/HCSPls+hV6rz9sVI+ZTXAne3qzGzVjUYwk96a2HmwWweo5qUNFW2pddPlCGVMI9YsjPWfnsFlYPqM2b0XUN5/ch8tu5ZbzW8e93rFgJgz1hBDiE0KIWUKIBv1W8pVNIvSyxblNHr7znjOxWQW3PvDShKt3+kO6Z6FtTBXtWQS10lmApnEYiyO9AU4MBTMUXM3S1uUnFpfcesF8PA7rmHSR9nf5aG2uZkZ9FVaLSImDDwxH8LrsKWqqAE0Jw9DtC7M3y8CjbNR7HEYYSs+TtDZrPQYz66sKehaj7fo9Z77mKZUqFKVvjGcUiL/rI2aTr9CHw1r/ih6Gqq2yMxgsPNMi2VjMSQwNKkaSe+P+HlbOqsPjTL0omFbrQspMZWW9+i/ZQzhjVh3bjw5kHW+7p3OIP23r4H1r5+Ysry41ZozFvwAfAjYAWxK3zaVc1GTjSF+A2io7XpedGXVV3PeuM9h1bHDC8xeBcAy3w2rExys1wR2NxRmOxIwr3ObqcRiLvmHikqwyG2bQQ0ArZ9VxxYrp/Hn7sVEpuMbjkoM9flqbPNitFmbUVaVsPv3DkYzkNmD8wXf7Quw94cvb96BT7x4xFnqeRPdmZta78/ZaDAUjHOoJjErSetHUaho9DjaVKMm99XA/sxvcBTe/abVaTiY5b6FXko2EoWzE4rJgBWCysah22miqdow7ye0LRdl+dMAoCkhmag65kq4h7X6ysVg1u45QNM5rxzIr8765fi9uu5VbziuPVwHmOrjnZbmVb8UVSHvfMLMaqoz7Fy6ewluXT+OJCZZ69oWieJw244q9UhvzdHVcfZ1TvGMzFv5Q1DASYzU2ezt9WC2CeU0erl09k0A4NqqhOB0DwwQjcVoTm/acRndKWKM/EMkom4URMcHtRwcIhGOm1EPrPQ6juqqty4/DZmF6nfa9m1XvpnMwlNOb3ZXYgEbT9SuEYE1rI5vaekrSs/PykX4jsZuPKV5tQ00xFolKskbPSBgKCnvT6QUHsxvc485ZvHigl1hccs78TGORS9uqyxcymjN1dA9r65HUUOiuY4P8efsxbnrDvIKhylJipoP7vdluE7G4yUJ73zAz69wpj5VDn0n3LGxWbbJapUp+6EasOhHHb6520hsIZ3W/85GsjHpiaGzVVHs6h5jb6MZps3LWnHpamzw8vNm8iF56OGhOY+rmM5Co6U+nKRE+0UtTTYWh3HbDOO7v8jO30W2M1NQronL1Rezs0KQkRjtZbU1rAx0DwaI3rx0bGOb4YLBgCAq05H6jx8GxpJyF/nvQcz9GUUeBC6R0YzGn0TNuyY+NbT3YrYIzZ9dnPDfNq30u6WXZXUMhmqodKeHJGXVVNNc4MxRov7l+LzVOGx84b9641jlezEiNvy7p/y7gYuAl4P6SrGiSIaWkvS/ABYuaUx6vrbITCMcIR+N5u2WLiT80kgfwumwV61no8uRe3VjUOJGJUNLURHzaDMmJ1zF7Fid8LG7RruqFEFyzeib3PL6bg91+5iY0h/KhC/kZxqLBw8BwhP5AmDq3g4HhCLMa3BnneV12rBbB5sT85Xw9Fjr1bgeDwQjRWJy2bh+LkkJX+nu09w0bXk4yOzoGafQ4jISqWfSr5Y37e4wYfzHQS0RXZdlgszHVm1o+qzdBNmV4FvkvkHTPQz9+TqOb3798lFA0llXI0Ayb2npYNaueKkfm+d4qG1V2a4ZncSIh9ZGMEIIzZtXx2PZjvJLI50jgQLefD1+80JjFXi7MhKFuT7rdDKwCyrvqCqLbFyYYiWdsCHqceqK8i2hiBrHbkTAWVeblDyYaXZ682qn9jqaMUfIjOaE7ltLbYCTGwR5/ykb9zjNnYhHknc6WTFu3X+sXScTd5zSmlmP2B8JZw1AWi6DB4yAYidPideVtStOpd9sNo3q4J2AYKBjxLHJVRO1MyJJnG6yUj/nN1TTXOIteQrv1SD8Oq4Ul08wN75mW1mvRk+ZZ1JosFx8YjqRUp81pdCMlHDEpxJjOYDDCq0cHWJMlBAWaAcjWgd41FGJKTeaF0c3ntXLpshaWzahl2YxaTp9Ry3Wvm1V2rwLGNsQoACws9kImK/ofp/7HqqMLxw0MhyekJjqQiFUEOfhrAAAgAElEQVR7nNrVjXcUHa0TjS+krasmybMAfWKe+TDJkd4ATpsFu9UyJs9i3wkfUqYqvU71ujh/UTO/famdO968yAjz5OJAt9YYp2/C+tX3od4Ay2fUGg1g2Wj0OOgaCuXVhEpGj1e/0j5ANC5TPIipXhd2a/Zei3BU6+V4/7mjTzXqeYuNibzFaI1NLl4+3M+yGZkDmHLRUutKmSbX6w/jtFnwOPTvuznVgoHhCDVOmxH+md2Q+Lx6/CxIa4o08/O+0NZLXJI1uW2s3ZvZVNg1FOL0LCHBs+c1cPa8yiw2NZOz+KMQ4tHE7U/AbuAPpV/a5ED/40z3LCa6IkkffGR4Fi57xfZZGJ5FurEY5Ybf3jfMzPoqptQ4xzRAae8JvRkudZO49qxZHBsI8sU/7mC4QHVNW5ffGOsJWsIU4FC3H184SlxmSn3o6GWfZkdj6l3cWw5pCdBkz8JqEUyvq8raE7HvhI9ITI5Z0vqc1kY6B0NF6x2KxOJsO9pvKl+hM63WRa8/bCTwu30hmqqdxmY+0luU/+9tcDh1auHcxuyNed9cv5e3fOvvDGSZ0JfMxrYeHDZL3kT9tNrUxrxYXNLtywxDVTpmgulfB+5N3L4KnC+l/HRJVzWJ0MsVZ9SlehZ66KG/wJetWOiDj0Y8C1vFh6FqnKnGYtRhqP4AsxrcY+7T2NPpw24VGbmJy05v4YY1c/jfjYe4/JsbeD5HCGY4rM2TSL7Cr3JYmep1cqg3YGw0uT0L7ec2k9yGEWPxkm4s0tadq9dih5HcHpuxWNOqXekWq99i9/EhgpG46XwFYOSy9Ma8ZF0oGPFSC+Us0j29Bo+DaqctJYHfORjku8/sY9exQT7+0Ct5K8E27u/hzNl1eceb6pIfumZYrz9MXHJSGovDwPNSymellM8BPUKIuSVd1STiSO8wDR5HRjNO7UQbi0TSONWzqExjoSe49T4Lp03rDRlt3uFI74hn0T0Wz6JziHmJ/ohkrBbBl95+Or+8+fXEJbx73Sa+8IdXM/ov9Cvt5Ct80JLch3sCOXWhdPTNzkxyG0bEBF9p76fB48hIeM6qd+cwFoNU2a3MHWOCel6Th6leJ0/uOsH29gHjpif3R4seTlo1Ks8itdeixzeiCwWalLnHYTVVDZX8eQghmN2Qqj77vaf3EY9LPnDuPNbv6uRHfzuQ9bX6A2F2HR/knNamvO/ZUusiGpd0J3pD9Aub0RYblBszOYuH0Maq6sQSj70u++EjCCEuA74JWIEfSSnvTnv+PuDCxF03MEVKWZd47h40OXQL8ATwEVmBAxra+wLMSstXwMQnuPXehZEYrh1fKEo8LjO6h8vNUDCC1SJw2Uc26dFKfgwGI1qlUb0buzU4pjDUnk4fy2fmzpGsnd/E4x89j//6625+9o+D9AYifPv6Vcbz+nS81qZUz2B2o5sNe7qSFGez14PMrK/CYbOwMI+AYDK6ZxGKxlk+I3Pjn1lfRbcvxHA4llKZs+VQH0unewvmX3IhhODcBVoe56nXUodkXnXGdL7wtmUpV/mFePlwP03Vjow8Xz5GxqvqxiIz11NroqhjYDhivJbOnEa3IVHf0T/Mr144wrWrZ/L/3rqE9r5h7n78NVbNrmP13NRcwvMHepGSrP0VKWvXvaIBLamtXxSdjJ6FTUpptMcm/l/wmyGEsALfBS4HlgLXCyGWJh8jpbxDSnmGlPIM4NvA7xLnrgXeAKwATkczTG809RNNMEf7hplZn1kaWeOyI8SIkFypCRhhKM3+11ZplTNDFZi3SNaF0hltF7c+RnRmvZvmGie+UNT4HZghEI5yuDeQUn6aDbfDxhfetoxbL5jPn7Z18NrxQeM5vcdiblPq5z+30c2JoZBRW58rZ/HPa+bwl4+cZ1qrye2wGmXY6d4MYHwPj/aPhFT2dg6x/egAlycG8YyVz12xhB+9d3XK7cMXLeCx7ce45L5nRyWeufVIH2fMqhtVsjx5vKqUkh5/mKa0zm8zRR0Dw9EMT29Oo4cjfQFiccn3ntmHRPKhCxcghOCea1cws76K2365NWVmOmghKJfdwspZ+YsydK9I/z7oCssno7HoEkJcqd8RQlwFmJH5PBvYJ6VsSxiYB4Gr8hx/PfCrxP8lWk+HA3ACdmBi26FNEI9LI8majtWiTfAaCIxNhiIbUkr+sb87ZV6Cji5zYOQsXJXbxT2U1A+iM8U7uiR1e1IVml622j1k/ne974TmFZjNF9x8Xiseh41vrt9rPNbW5WN6rcsI/enMToR7Xj2q5QpyhaFcdqsh12EGIYQxiztbL4WuIpBcBvrQlnZsFsE7Vs0w/T7ZqHM7eNPSqSm3j11yGn+8/Vym1VZx6wMvcesDWwpv1oEIbV3+UeUrQOv2r3HaOD4QxB+OEYrGM7yZQqFXKaUx+CiZOY1uIjHJ5oO9/PrFI7xr9SzD8Hpddr77njPpDYS57ZdbeWjzEeP29O4TrJ7TULCiK90rOpk9iw8CnxFCHBZCHAY+BfyrifNmAMmqbO2JxzIQQswB5gFPAUgpNwJPA8cSt79KKTOEloQQtwghNgshNnd1dZlYUnHp8oUIx+LMzNJ0BRhNWcViR8cg7/nh8zyXRZI7kJ6zqGB9qGQRQR3dszAbaUyuQtOnjY2mi3tPZ8JYtJjLF9S5HfzLufP4y6vHjVGgbd3+rJu2Ln39Snt+YzEW9FBUenIbRjwL3ZBGYnF+99JRLlo8pWTic4tbvDxy61o+ddli/vLqce7/x8G8x7/Sbk48MBv6XIteQ+ojzVhU5VctCEbihGPxTM8i8Xn9v9+/ikDwoQsXpDx/+oxavnjlMjYd6OHfH95m3A71BLjgtNRm3Gw0ehzYrcKoiOoaClHttGVcZFQ6BVcrpdwPrBFCVANCSml2/mQ2HzPXTnAd8LCUMgYghFgALEGb9w2a8u35UsoNaWtbB6wDWL169YTnM9pz9Fjo1LntRQ1D6SJy2fTxDc8iKcENlelZ+ILRlAExoF1lDUdi+MOxDEOSjSN9AdwOK/Vuu+FZjCaMtbdzCIfVYmwUZnj/ufP46XMH+Mb6PfzghrNo6/Jz9ZmZ1z96InnnsUFcdkveSpnRYhiLLEaqudqJw2YxDOmzu7vo9oW4tsSDcmxWC/92wXx++cIh9pzIn/TeergfIWBFnlxRLlpqXRwbDBqJ4owwlMvOa8Hc29NAWve2zpyE4d13wsd7z5lj6G0lc93Zs3nT0qkppdRWizC0n/JhsQim1LjoTPzdZuvengyY6bP4ihCiTkrpk1IOCSHqhRB3mXjtdiD5WzoT6Mhx7HWMhKAA3gFsSrynD/gLsMbEe04ours/K0vOArQrymJWQ+nVOH1ZFFZ1z6IqrUmpEvWhhkIRo8dCRxeLM7vht/cNM6vebczDgNF1ce/pHKK12YPNal6KpbbKzgfObeX/dnbyzO4ufKFo1iv8Wred2io74WjmVex4qfdoMiGzsxg5i0Uws67KaBR9aMsRmqodpq5+i8G8puqCFVIvH+lj4ZRq03maZLTmtmFDRDAjDFUgwZ2rOq3F68JhteCwWbj1ggXZTgU04zSrwW3cptdVmc67JPdadJ2sxgK4XEpptE5KKfuAt5g470VgoRBinhDCgWYQHk0/SAhxGlAPbEx6+DDwRiGETQhhR0tul29eaQ4KeRZmqjNGg17xlE2O2xeOGl94MK/CWQ58WcNQiVCSyfGqR3oDxu+9wePAIkbnWezp9JluhkvmpnPn4nXZ+Mwj24HsV/gwIvuRPiFvvJwzv4nLTm/JqTc2I9Fr0e0L8eSuE1x95syM0uBS0drk4UC3P2coUUqpKc3OGl2+QmdarYuuoZARbkwunQXNWAwlKgCzoXvZ6cbCahG8edlUbrtwQUalVLFIlvzoPomNhVUIYfxkQogqtKRzXqSUUbQpe39F2+h/I6XcIYT4YnLCHC2x/WBaWezDwH5gO/AK8IqU8o8m1jqhHOkdpqnamTPMUOwwlN54l81YBELalDwdvUu1IsNQiZGqyYzGO5BSJqrQNGNhtQiaqp2mm/p8oShH+4dNJ7eT8brs3HJ+q3GVmK0qCUZkP2pzVEKNlRvWzOG77zkz5/OzGtwc6Q3w+61HicYl1541M+exxWZ+s4dAOEZnjs/hUE+AvkCEM0zIkmejpbaKuMSY96A3Nep4XTatAjDHPJJ8TZLffc+ZfPji0qkYaeNVh5FSap5FmQYYjQczGZZfAE8KIX6auH8T8L9mXlxK+RjwWNpjn0+7f2eW82KYS6KXFa2DOHeteG2ilK9Ymjp6M1s2Y6HP39apdtgQojiexbb2fn70twNcf/bsgjXlZhgMRjPDUKOQ/BgcjjIUiqZIrDTXOE2HofYmBh6ZbYZL531r5/Kjvx9gOBxjem32z1/PhRQ7DFWImfVV9AUi/GLTIVbOqhvzzzgWdC+rrcuX9Qpdn9NgZoZFNvT8wI6OAdwOa4bKa/Ls+Wy/90JNkqWkpdZFMBKnczDEUCg6KT0LMwnue4QQ24A3oSWtHwfmlHphk4H2vmFWzMz9xa+rchCLy8SV9Pi/oLr+U2+WctxAKGaUzYIWv65x2salDxWMxPjG+r2s27AfCTz6Sgf/vGY2n758iakkdDZCUU22PT3JWFtlx24Vpspns4k3jqapb69eCTXGjbTGZeeLV53O3s6hnA2PI2GoiTYW2vse7Alw1wRPVdO9rP3dftYuyOxq3t6udZKbmQqYDV3yY9exoYwQFBQu6iinsdB7LbYlqsEmW/c2mFedPQ7EgXcBB4DflmxFk4RYXNLRP8xblk/LeYwegugPRIpiLAp5FumleOORKd9yqJd/f3gbbV1+3r16Fh+/ZBHrNrTx4+cO8PRrXXz16uWcv2j0iVOfIU+eulZLIpRkZsMfyRWNeBZTapzsOjaY65QU9nQO4bRZsiaJzXLlyul5n9fDULka8kqFribgtFl4W4E1FpsWrwu3w5ozyb2jY4DF02rG3EmuexbDkVjWUuARmfIcYSi9GqpMngVokxFh8vVYQJ6chRBikRDi80KIXcB30HomhJTyQinldyZshRXA/+04zg0/fp5QdKRsrnMwSCQmc1ZCQfGVZwP5chbhVM8CtCutsbz3468e45r/2UgoEufn7z+br12zgileF5+9YikPf3AtLruF9/7kBX7y9+yaOfnQDV42z2SKSe8gWxVac42Tbl84Z3IzmVc7BlgwpXrMm5YZdDXTiR5YoxvQS5e1TPgVtBDaeFq9sz0ZKaU2U2Pa2MQMQTO8zkRivymLvEghmXJdnryUn3sudGOxrf0kNBbAa2hT8d4mpTxXSvltNF2oU45/7O/hb3u7+U3SuE29lj2fvk1dkY2FXg01FIwSjsbTnsv0LGqrxiYm+LuXjjK9toq/3nE+5y1M9R7OmlPPnz98Hucvaua+9XsKSjinYyjOujKNhdlQUntfgBqnzdgcQOsxiMWl0YuSi1ePDrCprZc3L506qnWPlileF1+8ahlvH2fn9GhprnHy+SuW8olLTpvQ99WZ1+QxNLOSae8bZigYHfVY12SEGOlryKZFVSgMla17e6KYUuNEiBHPItvgo0onn7F4J1r46WkhxA+FEBeTvdHupEefyvXdp/YZevr63IBsIzN19KvKYvVa+JO0j/rTNkUtwZ2e8Bv9HO54XPL8gV7esKAxZ17CZbfy6csWMxSM8uO/t43q9dNnWSTTbHIuRXvfMDMb3KnaUjV6F3f+87+xfg9el41/Obf0k8fee87cDOn6ieBfzp3H7Maxh9jGQ2tzNe19wyleOIzIpI91poaOnrfIFoZKTnBnI98gqlJjt1q0WfP+MBaR3dhVOjmNhZTyESnlu4HFwDPAHcBUIcT3hRCXTND6KoJef0jTpRkM8uALh4ERz2J6Xe4rhGKHoZIlstOT3FqCOy1nMQaZ8p3HBhkYjhSselo63cvlp7fwk+cOZhiufBjy5M7MP9oWbxU9/hD3bzyYN5x0pC+Q4dGZaerb1t7P+l0nuPm81owEu6I4zG/2IGXmMKGdHYNYLcKYdz5WdM8iXeoDtPkoQpCzqKOcxgKS1l7tLEsobLyYmcHtl1I+IKW8Aq0L+2XglBp+1OMLs2Z+I2fPa+B7z+wnGInR3hdgqteZV0RMT272DxdHTNAfGpHC0PVxjOfC0UxjMYYEtz5reU2eMZE6H33TIvzhKD/8m3nvIn2kajI3nDOHcxc08fk/7OD6H27iYJbJbFJKo3s7GTOSH/c9sYc6t50b3zDX9HoVo0OXa09Pcu/oGGR+s2fc0ictiaqibNVQRgVgju/8YDCSErqcaHSvaDJWQoG5pjwDKWWvlPIHUsqLSrWgSqTbF6ap2sHH3ryIE0MhHnj+MEf6AnmT26CFa5w2y6jj+rnwh0d6C5I9i1hcEozEcaeHoVx2/OEYkVhqfiMfm9p6mNvoNkr98nFaSw1vWT6Nnz13MGvSPRv5wlANHgf3/8vZ3PPOFew8Nshl39zAj/7WluJl9PrDBMKxDM+iUFPf1sN9PL27i5vPay1KZZoiO/P08tm0JPeOjvElt3Xy5Swg/wVSpXgWkzG5DaM0Fqci8UTStNHjZE1rI+e0NvL9Z/bR1uU3NbxFb8wrBv5QzCiNTN6cjVkWGQlu7b7ZmRaxRL5iNI13H714IYFIjHUbzHkX+RLcoCUx3/W6WTxxxxtZO7+Ju/68i289NSILnquwwOO04XZYc3Zx37d+Lw0eB+9bO9fUOhVjo9ppY6rXmVIR1eMLcXwwOK7kts6CxKCoXGXP+UKv5TYWulc0Gbu3QRmLggwMR4jFpeH23vHmRXT7wpwYCmUdepROnbt4YoL+UJQZWY2Flkx0p5fOFkj4pbOjY4ChYNRUCEpn4dQa3rZiOvdvPEi3iQ7qoaCmYWVmBsCP37eaq8+cwTef3Mvf92qy7MnS5OlMydHFveVQLxv2dHHL+a1jbiZUmCe9Impnov9lvMltgLXzG/nbJy/MqcmVq6gjFI0RjBRf2HE0KM/iJEevhNLd3rPnNXBuojs1n9SHTl2Voyg5i1hcMhyJUVtlx+uypRgLPfGd7lmMVqZ8434tX3HOKIwFwIcvXkjQpHfhy6I4mwshBHe9/XQWNFfzkQe30jkYzNq9raOV3mYKEd73xF4aPQ7ee44SHpgIWpurjfnkgDH/Y1kRjIUQIm8FYq5y8XJ2b+ucUjmLUxF9lGKydv4nLj0Nt8PK6TMKu9XaqMfxy4TroaZqp43GRAneyHMJzyKnVo6599/U1kNrs8cYJmSWBVOquXRZC394+WjBY/WRqmZxO2x8/5/PZDgS4/ZfbuVQj586tz1r3iFb6e2Bbj9/39fNB85rnXTDZiYrrU0e+gMR4zu6o2OQGXVVE9Kg6HVlz1kMlrF7W2fh1Gq8LpupfaMSUcaiAOmeBWhTvl6981JTMdg6t70oo1X1hjy3w0a9255iLHJ1RRszLUx4FtFYnBcP9o3aq9BZNt1L52Co4BzsbFPyCrFgSg1fvXo5Lxzs5aHN7TlzRVNqXBnVUE/u0qbxXrEityyLorjMb06tiNrRMcCSIiS3zeCtsmctna0Ez6Kp2sm2Oy9l9dyGsq1hPKhLrQLoxiK9VC+XgFw6dVXZZcqllHzzyb0cT5t6d/nyabwxi+aS3pDncVpp8DgNfSQY8TrcWfoswFyfx/ajA/hC0TGryupzpw/3BljckntjGMoiT26Gq86YwfMHevnl84eZWZc9DNFc42QoGCUYiRklmk/s7GRxS03e0IWiuOiCgm1dfpZO99LW7eeKFROjU+V12fGFokRj8ZTBVpVgLCY7ylgUQA9D1Y/Rha6tshMIa0qryQNrjvQO8431e6mtsuOya4/3+SMc6QtkNxZJeYkGj53tR5NzFvpI1dQwVO0oEtwbR9FfkQ1dkvtQTwFjEYyOuav581cspXMgyMVLpmR9PrnXYlaDm/5AmM2H+vi3N84f0/spxsbMejd2q2B/t4/Xjg8hZXGS22bwJlUA1idFA/RQrDIWY0cZiwL0+sPUue1jnjamN+YNDEdSqiAO9WoJwHU3nMXrExv0TT99gW5f9pCVYRCcNho8Ws5Cn5ORy7NwO6xYLcJUGGpTWy8Lp1RnzDU2iz53+nBa5246vlCEGtfYunhddis/vvF1OZ/Xf78nEsbimd1dxOKSN5VYB0qRitUimNOoCQoWM7ltBuMCKRhJMRbKsxg/KmdRgB5fOKu0gFlqEx7JQFpF1MHEpqpLWYOeDM++sRuehdNKg8dOJCaNXEUuz0IIgddVWB8qEouz+eDo+ivS0edOH+zJ7LpOZrQJ7tHQnDZA6YldnTTXOFkxSROKkxl9xOqOjkFqq+wTppE1Mk449TtfTnnykwVlLArQ7QtljG8cDbn0oQ73+HHaLClldPlUYkdyFppnASO9FoZnkaXax2tCeXZbez+BcGzMyW2dOY1uDvfm9iyklGNKcJtlSlIXdzga59ndXVy8eIrp/JKieLQ2V3Oox8/2o/0sneYtyqRIM3irspeLDwxHcDusEzaP/GRE/eYK0OsPZ9WhMYsuU57emHeoJ8DsBnfKRqaX/WUbeD/iPWg5C31tAP5wDLtVpOREkl+zUIJb7694/biNhSdDQC6ZUDRONC5N91mMlgaPAyGgazDICwd68YWivGmJCkGVg9ZmD5GY5NWjgxMWgoLcMy3K3b19MqCMRQF6/OFxyQnXuXMbi+QQFGhf9LjUNv90UsNQqZ6FP5QpIqhTa0JM8O/7ulncUjNu2eQ5DW6O9g/n1KLSr/ZKpc1ks1po9Ghd3Ot3deKyW3hDlvGeitIzv3nkuz1RyW1IDkMpY1FslLHIgz5MJ5t2vlmyhaGklBzq9RtzmnVyfdFhJAzldthoSORBRoxFLKN723jNqvxzuI/2D/P8gV4uWdZi9kfKyexGN7G45GhCkiMdfaRqTQklN5prnJwYDPHEzk7OXdBElWN8KqeKsaGrzwJF0YQyS22eMJTKV4wPZSzy0BcIIyU0jSMMVeOyIwQpvRYnhkIEI/FMY5Hjiw6a91Bl16qb6tPCUIFwNKN723jNHB2tOr/b0o6UcO1ZM0f3g2VBr4g6lCNvYcyyKFEYCjRj8eLBXo72D6sQVBmp9zioc9tx2CxG38VEYFQApiW4B5VnMW5U6WweenyZ3dujxZpFY/9QlkooSPJCsggP+pNmbFc7bTisFkOm3B+OZZTN6uRLcEspefildta0NhSlaU03fod7/EBmr4ghT15Kz6LaaXhSF+Xox1BMDKdNrSEci09oUtmoAMziWZyujMW4UMYiDz1+rQRzPNVQoI1XTZ4mdyhRXjqnIUcYKkvYKDkvIYTmXegDkAKhzJGqI69pIxiJE4rGMpReXzjQy6GeAB+5eOEYf7JUptQ4cdktRllwOvlmWRQLfWLeGbPqJuWc45OJr1+7sizvm60EXXkW40cZizzonsV4qqEgIVOe5llYLcKQG9cxtJyy5SxCsZTS2AaPk74kzyKXSFuymGBzTaqx+M3mdqqdNi4/vTi6SUII5jTkrogaSlztlXKkqd7F/SblVZSdckmspIdeI7E4/nBMGYtxonIWedClPsbTlAeZA5AO9QaYUVeV4Z7nkxT3h6JUJ82raPDYU3IWHmd2z6IloSD7xM7OlMd9oSiPbT/GFSumFTUJPLvRzeHe7I15uQQPi8n8KdXYLILLTh9/wl4xOWmpdfFK+wAnBjXdtUHVvV0UlLHIQ68/jBCMW1q5tsqekoc43JNZCQUjid9sHdeBtBnbuuQH5C+dvXjJVM5d0MR//nGHIb0A8Ni2YwxHYly7evyJ7WTmNLg51BNIGYWq45uAMNT5C5t4/jMXs2DK2CRFFJOfT156GsPhGLf/aivRWFxJfRQJZSzy0O0P0+B2YB1nB3B6GOpgoiEvHZvVQrXTlrWJzheKppTHNiTJlGuls9m9A6tF8I3rzqC2ys6HfvmSEQp6aMsRWps9nDm7flw/WzpzmjyEovGMuRKgKc667JaSJjyFEOMqdVZMfhZOreHL7zid5w/0ct/6PcpYFAllLPLQ6xtf97aOHoaSUjIQiDAwHDHKTNPJVskB2oAjT0oYSqv6CUVjDEdieQf7NFU7+fb1qzjcG+DTv91OW5ePFw/2ce1Zs4ouwzCiPpsZitKkPtQfrKL0XH3mTK4/exbffXo/f3i5AxjJCSrGhjIWeejxh8bd1QzaaNVYXBP+09VmZ2cJQ0Gi1DWHZ5Ga4NY23Y5+LS6bK2eh8/rWRj5xyWn8efsxPviLLVgEXH3mjDH9PPnQw2vZkty+UBRvCUNQCkUyX3jbMpZM8/KzfxwElGcxXpSxyEOPb3zd2zq1SZIfI2qzOYyFK7MvQkqZSHCn5iwAjiQa4MyMDP3X81u5ePEU9nT6eOOiZmMmcDGZUVeFzSIMo5jMUND8/G2FYry47Fa+909nGn83qoN7fChjkYce//jkyXWSJT8OJ8Iz2XIWkJDnSEtwh6Jx4hLcSd6D3sXdnpDWKORZgDbd7953reTSZVO5vUi9FenYrBZm1Fdl9yxKqDirUGRjXpOHb11/Bm9eOnXc/VKnOuovNweRRBVFMb5gdUnG4lBPgCk1zpyegNdl57XgUMpj2UpO9fDYkT7zngVolV0/uGH16H6AUTI7URGVzlAwytwmNd5UMbFctHgqFy1W0i/jpaSehRDiMiHEbiHEPiHEp7M8f58Q4uXEbY8Qoj/pudlCiP8TQuwSQuwUQswt5VrT6UtUGjUUIcGtl972ByIJtdncG2a27tNAQp48NWeRMBaJMFQlXbHPbfRkTXD7QirBrVBMVkq2wwghrMB3gTcD7cCLQohHpZQ79WOklHckHX87sCrpJe4HviylfEIIUQ1k170uEfp406Yih6EO9fo5d0GmbpKOt0obOB+PS2PWxYhnkRSGShggPQyVS0iwHMxpdDMYjNIfCKf0qAwFIyUVEcperQoAABWASURBVFQoFKWjlJ7F2cA+KWWblDIMPAhclef464FfAQghlgI2KeUTAFJKn5Qy/3DncRCMxBhOmyFh6EIVIcGtz7Q4PjBM52CIufk8C5cNKbWeBJ1sk/DsVgtel432RBgqV1NeOdDzMckaUVJq1WDKWCgUk5NSGosZwJGk++2JxzIQQswB5gFPJR5aBPQLIX4nhNgqhPivhKdSdI70Bljxn//HH1/pSHlcb3grRumsy27FabOw/egAkLtsFpK1nEZCUb7QyEjVZBo8DsMDqiTPYm5TQqo8KRR1oNtPXJZWF0qhUJSOUhqLbN1emRoQGtcBD0sp9ct7G3Ae8AngdUArcGPGGwhxixBisxBic1dX15gWObO+Cq/Lxqa2npTHjTBUEXIWoIWitrVrxiJdmjyZbPpQgYTXk17xlGzIcg0/Kge6Z3E44VkEI5r0Qm2VnbesKI5ooUKhmFhKaSzagVlJ92cCHTmOvY5ECCrp3K2JEFYU+D1wZvpJUsp1UsrVUsrVzc258wD5EELw+tZGNrb1pMy+7vWHsFpE0a6E69x2ehLeSr4wVLbJeoZn4cj0LHTcJkpnJwqX3cpUr9MIQ33xTzvZ0THIf79rJTPqqgqcrVAoKpFSGosXgYVCiHlCCAeaQXg0/SAhxGlAPbAx7dx6IYRuAS4CdqafWyzWtDZybCCYUu7Z49Nmb1vGqQulU1elbexely2vMOGITPlIzsKfJwwFYLMIHBM4YMYMcxo9HO718/utR/nl84f54Bvnc7GaXKdQTFpKtsMkPILbgL8Cu4DfSCl3CCG+KIS4MunQ64EHZdJlfSIc9QngSSHEdrSQ1g9LtdZzWhsB2JgUiur2FachT0fPReQLQcHowlD1ifV5nLaiazyNlzkNbl47NsRnHtnO2XMb+MQli8q9JIVCMQ5KGuiWUj4GPJb22OfT7t+Z49wngBUlW1wS85s9NNc42dTWw/Vnzwa0MFQxRAR19IqofD0WkDvBnc17aEh4KLkUZ8vJnEY3Q6EojR4H337PKmwV5vkoFIrRof6C0fIW57Q2snH/SN5Ck/oonjxAXZU5Y1HjtCFE6mjVQGJeRbr3oIehcs3fLienz6jFZhF887pVJdGgUigUE4syFgnWtDZyYihEW7dW7qnnLIqFnrie05A/DGWxCGqctjTPIvu8Cn19lehZXHDaFF75wiWcu7Cp3EtRKBRFQBmLBOfMT+Qt9vcQjMTwhaJFK5sF82EoyJQpT5+Sp2N4FhVUNptMJTUKKhSK8aGMRYK5jW5avC42tfUkNeQVLwx1xqx6FrfUsHiat+Cx6TLlvhxjUw3PooLKZhUKxcmJuvRLIIRgTWsDf9/XQ0+iIa+YCe7lM2t5/KPnmzo2XaY8fUqeTqV7FgqF4uRBeRZJnDO/kW5fiOcPaCW0xQxDjYZ0z8KfNn9bp9ppw24VKtyjUChKjtplkjinVUvG/mnbMaC4YajRUJuWs/DnyFkIIbjl/FbOntc4kctTKBSnIMpYJDGroYoZdVW8fEQbq1HMMNRoSJ9p4Q9lD0MB/PuliydqWQqF4hRGhaGS0HSiGgCwW7US1nLgddnxh2NEY9oID1+OMJRCoVBMFMpYpKFLfzR6nGWT0ND1oYaCUSKxOOFoXOUlFApFWVE7UBp6v0UxG/JGS7I+lCVhsCppXoVCoTj1UMYijZn1bmY3uJnqLU9yG0a6vQeHo9gTmkqVNGNboTBDJBKhvb2dYDBY7qUoAJfLxcyZM7HbxzZ2Qe1AWfjBDWfhtJUvQudNmmnhsmvrqET9J4UiH+3t7dTU1DB37tyKU0U+1ZBS0tPTQ3t7O/PmzRvTa6icRRaWTPPS2lxdtvc3ZloEI/gT8uTVqktbMckIBoM0NjYqQ1EBCCFobGwcl5enjEUFYuQshiPG4CPVpa2YjChDUTmM97NQxqICMWZaBEeMhcpZKBSKcqKMRQXicVixWgSDw1H8Yd2zUGEohaJSiUajhQ+a5ChjUYEIIfC6bAnPQs9ZKM9CoRgLb3/72znrrLNYtmwZ69atA+Dxxx/nzDPPZOXKlVx88cUA+Hw+brrpJpYvX86KFSv47W9/C0B19Uj+8uGHH+bGG28E4MYbb+RjH/sYF154IZ/61Kd44YUXWLt2LatWrWLt2rXs3r0bgFgsxic+8Qnjdb/97W/z5JNP8o53vMN43SeeeIKrr756In4dY0btQBWKLvlh5CyUsVBMYv7zjzvY2TFY1NdcOt3LF962rOBxP/nJT2hoaGB4eJjXve51XHXVVdx8881s2LCBefPm0dvbC8CXvvQlamtr2b59OwB9fX0FX3vPnj2sX78eq9XK4OAgGzZswGazsX79ej7zmc/w29/+lnXr1nHgwAG2bt2KzWajt7eX+vp6PvShD9HV1UVzczM//elPuemmm8b3CykxageqULwue2qC267CUArFWPjWt77FI488AsCRI0dYt24d559/vlFC2tCgSfysX7+eBx980Divvr6+4Gtfe+21WK3a3+bAwADve9/72Lt3L0IIIpGI8bof/OAHsdlsKe93ww038Itf/IKbbrqJjRs3cv/99xfpJy4NylhUKN4qG4PBKP6wNlLVYlFVJYrJixkPoBQ888wzrF+/no0bN+J2u7ngggtYuXKlESJKRkqZtWIo+bH00lOPZ2RM8uc+9zkuvPBCHnnkEQ4ePMgFF1yQ93Vvuukm3va2t+Fyubj22msNY1KpqJxFhZLsWagQlEIxNgYGBqivr8ftdvPaa6+xadMmQqEQzz77LAcOHAAwwlCXXHIJ3/nOd4xz9TDU1KlT2bVrF/F43PBQcr3XjBkzAPjZz35mPH7JJZfwP//zP0YSXH+/6dOnM336dO666y4jD1LJKGNRodRW2Y2mPJXcVijGxmWXXUY0GmXFihV87nOfY82aNTQ3N7Nu3TquvvpqVq5cybvf/W4APvvZz9LX18fpp5/OypUrefrppwG4++67ueKKK7jooouYNm1azvf65Cc/yX/8x3/whje8gVgsZjz+gQ98gNmzZ7NixQpWrlzJL3/5S+O5f/qnf2LWrFksXbq0RL+B4iGklOVeQ1FYvXq13Lx5c7mXUTS+8tgu7t94kLXzm+gcDPLnD59X7iUpFKNi165dLFmypNzLqGhuu+02Vq1axfvf//4Jeb9sn4kQYouUcnWhc9Ula4XiddkIRuL0BcJKnlyhOAk566yz8Hg83HvvveVeiinULlSh6F3cxweCLG6pKfNqFApFsdmyZUu5lzAqVM6iQtH1oToHg8qzUCgUZUcZiwpFn2kRl6iRqgqFouwoY1Gh6DLlgPIsFApF2VHGokLRw1AAHjXLQqFQlBllLCoUPcENyrNQKBTlRxmLCiXFs1Dy5ArFhJCsMKtIRRmLCsVlt+Cwah+P8iwUilOLSpyPUdJdSAhxGfBNwAr8SEp5d9rz9wEXJu66gSlSyrqk573ALuARKeVtpVxrpSGEwFtlo9sXViNVFZOfv3wajm8v7mu2LIfL7857yKc+9SnmzJnDrbfeCsCdd96JEIINGzbQ19dHJBLhrrvu4qqrrir4dj6fj6uuuirreffffz9f//rXEUKwYsUKfv7zn9PZ2ckHP/hB2traAPj+97/P9OnTueKKK3j11VcB+PrXv47P5+POO+/kggsuYO3atTz33HNceeWVLFq0iLvuuotwOExjYyMPPPAAU6dOxefzcfvtt7N582aEEHzhC1+gv7+fV199lfvuuw+AH/7wh+zatYv//u//HvOvN52S7UJCCCvwXeDNQDvwohDiUSnlTv0YKeUdScffDqxKe5kvAc+Wao2Vjtdlp9sXVtpQCsUYue666/joRz9qGIvf/OY3PP7449xxxx14vV66u7tZs2YNV155ZcEZ1S6Xi0ceeSTjvJ07d/LlL3+Z5557jqamJkMo8MMf/jBvfOMbeeSRR4jFYvh8voIzMvr7+3n2WW3L6+vrY9OmTQgh+NGPfsQ999zDvffem3XuhsPhYMWKFdxzzz3Y7XZ++tOf8oMf/GC8v74USrkLnQ3sk1K2AQghHgSuAnbmOP564Av6HSHEWcBU4HGgoG7JyUhNIsntVtVQislOAQ+gVKxatYoTJ07Q0dFBV1cX9fX1TJs2jTvuuIMNGzZgsVg4evQonZ2dtLS05H0tKSWf+cxnMs576qmnuOaaa2hqagJG5lU89dRTxowKq9VKbW1tQWOhixoCtLe38+53v5tjx44RDoeN+Ru55m5cdNFF/OlPf2LJkiVEIhGWL18+yt9WfkppLGYAR5LutwOvz3agEGIOMA94KnHfAtwL3ABcXMI1VjRel/bxKM9CoRg711xzDQ8//DDHjx/nuuuu44EHHqCrq4stW7Zgt9uZO3duxpyKbOQ6L9e8imzYbDbi8bhxP998jNtvv52PfexjXHnllTzzzDPceeed8P/bu/vYuuo6juPvT7ayDhDnYFuWFRlEQqUZ3VizghNRqoaRhsQ4xuqCaFhIECIPRoUsWdAQIolRRiQzqAgmexCnKFkUWGYl8SGFAoOtjg3QkVUeOm4cw4csgF//OL87LuXe3W7r3TldP6/k5pzz2+ntp3e/7dvzOw8/as+PsXz5cm6//XZaW1sbMuteI09wV/v0aj3idimwISLKz/X9CvDbiNhdY//sG0hXS+qX1L9nz54jiFpM5ctnfYLb7PAtXbqU9evXs2HDBhYvXswbb7zB9OnTaWpqore3l5deemlE71Pr67q6unjggQcolUrAu/NVdHV1sXr1aiCbh3vfvn3MmDGDoaEhSqUS+/fvZ+PGjQf9fuX5Me6///4D7bXm3ejs7GT37t2sXbuWnp6ekX48I9bIYjEInFqx3QK8XGPfpcC6iu3zgesk7QK+C3xR0vuOYyPinojoiIiOadOmjU7qAik/8sOXzpodvra2Nt58801mzZrFzJkzWbZsGf39/XR0dLBmzRpaW1tH9D61vq6trY0VK1Zw4YUX0t7ezk033QTAqlWr6O3tZc6cOcyfP5+BgQGamppYuXIlnZ2ddHd3H/R733rrrVx22WVccMEFB4a4oPa8GwBLlixh4cKFI5oS9lA1bD4LSROBnWTDSP8AngC+EBEDw/Y7C3gEOD2qhJH0JaCj3tVQx9p8FgDf+d1z/PCxF9l52yKOm+irnG1s8XwWR193dzc33ngjXV3VR+8LOZ9FRLwt6TqyQjABuDciBiR9G+iPiIfSrj3A+mqFYrz73LxZTD2hyYXCzA5q7969LFiwgPb29pqF4kh5pjwza4ixemSxdetWrrjiive0TZo0ib6+vpwSjZ5CHlmYmY1Fc+bMYcuWLXnHKByPb5hZwxwrIxfHgiP9u3CxMLOGaG5uplQquWAUQERQKpVobm4+7PfwMJSZNURLSwuDg4Mci/dAjUXNzc20tLQc9te7WJhZQzQ1NR14RIWNfR6GMjOzulwszMysLhcLMzOr65i5KU/SHmBkTwSr7hTg9VGK02hjJetYyQnO2ijO2hijmfW0iKj7cL1jplgcKUn9I7mLsQjGStaxkhOctVGctTHyyOphKDMzq8vFwszM6nKxeNc9eQc4BGMl61jJCc7aKM7aGEc9q89ZmJlZXT6yMDOzusZ9sZB0saQdkl6QdHPeeSpJulfSkKRtFW1TJW2S9Hxajv78iYdB0qmSeiVtlzQg6frUXri8kpolPS7pmZT1W6n9dEl9KevPJR2Xd1YASRMkPS1pY9ouZE4ASbskbZW0RVJ/aitiH5giaYOk51KfPb+gOc9Kn2X5tU/SDXlkHdfFQtIE4G5gEXA20CPp7HxTvcd9wMXD2m4GNkfEmcDmtF0EbwNfi4iPAucB16bPsoh59wMXRUQ7MBe4WNJ5wB3A91PWfwJX5Zix0vXA9ortouYs+1REzK24tLOIfWAV8HBEtALtZJ9v4XJGxI70Wc4F5gP/AR4kj6wRMW5fwPnAIxXbtwC35J1rWMbZwLaK7R3AzLQ+E9iRd8YauX8DfKboeYHjgaeATrKbnCZW6xs55msh+8/gImAjoCLmrMi7CzhlWFuh+gBwEvB30jnbouaskvuzwJ/yyjqujyyAWcDuiu3B1FZkMyLiFYC0nJ5znveRNBuYB/RR0LxpaGcLMARsAl4E9kbE22mXovSFO4FvAP9L2ydTzJxlATwq6UlJV6e2ovWBM4A9wE/T8N6PJZ1A8XIOtxRYl9aPetbxXixUpc2Xhx0BSScCvwRuiIh9eeepJSLeiezQvgVYAFSbLDrXviCpGxiKiCcrm6vsWqQ+uzAiziUb2r1W0ifyDlTFROBcYHVEzAP+TQGGnA4mnZe6FPhFXhnGe7EYBE6t2G4BXs4py0i9JmkmQFoO5ZznAElNZIViTUT8KjUXNi9AROwF/kB2nmWKpPIcL0XoCwuBSyXtAtaTDUXdSfFyHhARL6flENnY+gKK1wcGgcGI6EvbG8iKR9FyVloEPBURr6Xto551vBeLJ4Az09Ulx5Ed5j2Uc6Z6HgKuTOtXkp0byJ0kAT8BtkfE9yr+qHB5JU2TNCWtTwY+TXaCsxdYnHbLPWtE3BIRLRExm6xv/j4illGwnGWSTpD0gfI62Rj7NgrWByLiVWC3pLNSUxfwVwqWc5ge3h2Cgjyy5n3SJu8XcAmwk2zMekXeeYZlWwe8ArxF9tvQVWRj1puB59Nyat45U9aPkw2HPAtsSa9LipgXOAd4OmXdBqxM7WcAjwMvkB3uT8o7a0XmTwIbi5wz5XomvQbK/54K2gfmAv2pD/wa+FARc6asxwMl4IMVbUc9q+/gNjOzusb7MJSZmY2Ai4WZmdXlYmFmZnW5WJiZWV0uFmZmVpeLhdkhkPTOsKeAjtqdv5JmVz5h2KxIJtbfxcwq/Deyx4SYjSs+sjAbBWkehzvSPBmPS/pIaj9N0mZJz6blh1P7DEkPpjk1npH0sfRWEyT9KM2z8Wi6w9wsdy4WZodm8rBhqMsr/mxfRCwAfkD2DCfS+s8i4hxgDXBXar8LeCyyOTXOJbvjGeBM4O6IaAP2Ap9v8M9jNiK+g9vsEEj6V0ScWKV9F9mESn9LD1R8NSJOlvQ62bwDb6X2VyLiFEl7gJaI2F/xHrOBTZFNaIOkbwJNEXFb438ys4PzkYXZ6Ika67X2qWZ/xfo7+LyiFYSLhdnoubxi+Ze0/meyJ8YCLAP+mNY3A9fAgYmYTjpaIc0Oh39rMTs0k9MMe2UPR0T58tlJkvrIfgnrSW1fBe6V9HWy2dm+nNqvB+6RdBXZEcQ1ZE8YNiskn7MwGwXpnEVHRLyedxazRvAwlJmZ1eUjCzMzq8tHFmZmVpeLhZmZ1eViYWZmdblYmJlZXS4WZmZWl4uFmZnV9X8yf/lySNCz/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history1.history['accuracy'], label='accuracy')\n",
    "plt.plot(history1.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "fig.savefig('../figures/model0_val_training_curve.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1 - 1s - loss: 0.2779 - accuracy: 0.8390\n",
      "0.839\n"
     ]
    }
   ],
   "source": [
    "test_images = X[1000:2000,:,:,:]\n",
    "test_labels = Y[1000:2000]\n",
    "test_loss, test_acc = model[0].evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05878075, 0.9412192 ],\n",
       "       [0.9955569 , 0.00444308],\n",
       "       [0.9238999 , 0.07610016],\n",
       "       ...,\n",
       "       [0.24642698, 0.75357306],\n",
       "       [0.9864406 , 0.01355936],\n",
       "       [0.0516157 , 0.9483843 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([model[0], \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "probability_model.predict_proba(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "xy = X[0,0,6,:,:]\n",
    "\n",
    "plt.imshow(xy, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model:\n",
    "\n",
    "The model is initialized using the function `cascade_model`, which returns a list of two `NeuralNet` objects. Optimized weights are stored also inside the experiment folder for future use (testing different images without re-training the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options['weight_paths'] = os.getcwd()\n",
    "model = cascade_model(options)\n",
    "model[0].summary()\n",
    "model[1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:\n",
    "\n",
    "The function `train_cascaded_model` is used to train the model. The next image summarizes the training procedure. For further information about how this function optimizes the two CNN, please consult the original paper. (**NOTE**: For this example, `options['net_verbose`] has been set to `0` for simplicity)\n",
    "\n",
    "\n",
    "![](pipeline_training.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model, history1, history2 = train_cascaded_model(model, train_x_data, train_y_data,  options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model:\n",
    "\n",
    "Once the model has been trained, it can e tested on other images. Please note that the same image modalities have to be used. Testing images are loaded equally to training_data, so a `dictionary` defines the modalities used:\n",
    "\n",
    "```\n",
    "test_X_data['image_identifier'] = {'modality_1': /path/to/image_modality_n.nii.gz/,\n",
    "                                         ....\n",
    "                                   'modality_n': /path/to/image_modality_n.nii.gz/}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST X DATA\n",
    "test_folder = '/mnt/DATA/w/CNN/images/test_images'\n",
    "test_x_data = {}\n",
    "test_x_data['im1'] = {'T1': os.path.join(test_folder,'im1', 'T1.nii.gz'), \n",
    "                       'FLAIR': os.path.join(test_folder,'im1', 'FLAIR.nii.gz')}\n",
    "\n",
    "\n",
    "# set the output_location of the final segmentation. In this particular example, \n",
    "# we are training and testing on the same images\n",
    "options['test_folder'] = test_folder\n",
    "options['test_scan'] = 'im1'\n",
    "out_seg = test_cascaded_model(model, test_x_data, options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute different metrics on tested data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "# load the GT annotation for the tested image \n",
    "GT = nib.load(os.path.join(test_folder,'im1', 'lesion_bin.nii.gz')).get_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
